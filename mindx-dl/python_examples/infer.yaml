apiVersion: batch/v1
kind: Job
metadata:
  name: {{ infer_job_name }}
spec:
    template:
      spec:
        # Select inference processor node
        nodeSelector:
          {{ node_selector }}
        containers:
        # Docker image for inference
        - image: {{ docker_image }}
          imagePullPolicy: IfNotPresent
          name: resnet50infer
          resources:
            requests:
              # If using A300I Pro, change 'huawei-Ascend310' to 'huawei-Ascend710'
              # number of Ascend-310
              huawei.com/Ascend310: {{ npu_count }}
            limits:
              # If using A300I Pro, change 'huawei-Ascend310' to 'huawei-Ascend710'
              # It needs to be consistent with the number of requests above
              huawei.com/Ascend310: {{ npu_count }}
          volumeMounts:
          # Ensure that the container time is consistent with the host
          - name: localtime
            mountPath: /etc/localtime
        volumes:
        - name: localtime
          hostPath:
            path: /etc/localtime
        restartPolicy: OnFailure